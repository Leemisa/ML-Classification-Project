{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4da69c55",
   "metadata": {},
   "source": [
    "# Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caddd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # For reading and manipulating structured data (like CSV files)\n",
    "import pandas as pd # For numerical operations and array handling\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dc96cc",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fb1ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Dataset/Loan.csv') #Using pandas to load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37af71f7",
   "metadata": {},
   "source": [
    "# Displaying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8dca0002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID  year loan_limit             Gender approv_in_adv loan_purpose  \\\n",
      "0        24913  2019         cf             Female         nopre           p3   \n",
      "1        24914  2019         cf               Male         nopre           p3   \n",
      "2        24915  2019        NaN              Joint         nopre           p3   \n",
      "3        24916  2019         cf              Joint         nopre           p1   \n",
      "4        24917  2019         cf  Sex Not Available         nopre           p4   \n",
      "...        ...   ...        ...                ...           ...          ...   \n",
      "148642  173555  2019         cf  Sex Not Available         nopre           p3   \n",
      "148643  173556  2019         cf               Male         nopre           p1   \n",
      "148644  173557  2019         cf               Male         nopre           p4   \n",
      "148645  173558  2019         cf             Female         nopre           p4   \n",
      "148646  173559  2019         cf             Female         nopre           p3   \n",
      "\n",
      "       Credit_Worthiness open_credit business_or_commercial  loan_amount  ...  \\\n",
      "0                     l1        nopc                  nob/c       316500  ...   \n",
      "1                     l2        nopc                  nob/c       336500  ...   \n",
      "2                     l1        nopc                  nob/c       426500  ...   \n",
      "3                     l1        nopc                  nob/c       476500  ...   \n",
      "4                     l1        nopc                  nob/c       196500  ...   \n",
      "...                  ...         ...                    ...          ...  ...   \n",
      "148642                l1        nopc                  nob/c       436500  ...   \n",
      "148643                l1        nopc                  nob/c       586500  ...   \n",
      "148644                l1        nopc                  nob/c       446500  ...   \n",
      "148645                l1        nopc                  nob/c       196500  ...   \n",
      "148646                l1        nopc                  nob/c       406500  ...   \n",
      "\n",
      "        income  credit_type  Credit_Score  co-applicant_credit_type    age  \\\n",
      "0       2760.0          CIB           620                       CIB  65-74   \n",
      "1       4980.0          CIB           846                       CIB  35-44   \n",
      "2       8940.0          EXP           533                       EXP  45-54   \n",
      "3       6780.0         EQUI           518                       EXP  45-54   \n",
      "4       3840.0          EXP           812                       EXP  25-34   \n",
      "...        ...          ...           ...                       ...    ...   \n",
      "148642  7860.0          CIB           659                       EXP  55-64   \n",
      "148643  7140.0          CIB           569                       CIB  25-34   \n",
      "148644  6900.0          CIB           702                       EXP  45-54   \n",
      "148645  7140.0          EXP           737                       EXP  55-64   \n",
      "148646  7260.0          CIB           830                       CIB  45-54   \n",
      "\n",
      "              LTV Region  Security_Type Status dtir1  \n",
      "0       62.303150  south         direct      0  44.0  \n",
      "1       78.621495  south         direct      0  35.0  \n",
      "2       75.088028  North         direct      0  34.0  \n",
      "3             NaN  south         direct      1   NaN  \n",
      "4       76.162791  south         direct      0  49.0  \n",
      "...           ...    ...            ...    ...   ...  \n",
      "148642  71.792763  south         direct      0  48.0  \n",
      "148643  74.428934  south         direct      0  15.0  \n",
      "148644  61.332418  North         direct      0  49.0  \n",
      "148645  70.683453  North         direct      0  29.0  \n",
      "148646  72.849462  North         direct      0  44.0  \n",
      "\n",
      "[148647 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7faf567",
   "metadata": {},
   "source": [
    "# Selecting Only Important data for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c7abcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       loan_limit             Gender approv_in_adv loan_purpose  \\\n",
      "0              cf             Female         nopre           p3   \n",
      "1              cf               Male         nopre           p3   \n",
      "3              cf              Joint         nopre           p1   \n",
      "4              cf  Sex Not Available         nopre           p4   \n",
      "5              cf             Female         nopre           p1   \n",
      "...           ...                ...           ...          ...   \n",
      "148642         cf  Sex Not Available         nopre           p3   \n",
      "148643         cf               Male         nopre           p1   \n",
      "148644         cf               Male         nopre           p4   \n",
      "148645         cf             Female         nopre           p4   \n",
      "148646         cf             Female         nopre           p3   \n",
      "\n",
      "       Credit_Worthiness open_credit business_or_commercial Neg_ammortization  \\\n",
      "0                     l1        nopc                  nob/c           not_neg   \n",
      "1                     l2        nopc                  nob/c           not_neg   \n",
      "3                     l1        nopc                  nob/c           not_neg   \n",
      "4                     l1        nopc                  nob/c           not_neg   \n",
      "5                     l1        nopc                  nob/c           not_neg   \n",
      "...                  ...         ...                    ...               ...   \n",
      "148642                l1        nopc                  nob/c           not_neg   \n",
      "148643                l1        nopc                  nob/c           not_neg   \n",
      "148644                l1        nopc                  nob/c           not_neg   \n",
      "148645                l1        nopc                  nob/c           not_neg   \n",
      "148646                l1        nopc                  nob/c           not_neg   \n",
      "\n",
      "       interest_only lump_sum_payment Secured_by total_units credit_type  \\\n",
      "0            not_int         not_lpsm       home          1U         CIB   \n",
      "1            not_int         not_lpsm       home          1U         CIB   \n",
      "3            not_int         not_lpsm       home          1U        EQUI   \n",
      "4            not_int         not_lpsm       home          1U         EXP   \n",
      "5            not_int         not_lpsm       home          1U        CRIF   \n",
      "...              ...              ...        ...         ...         ...   \n",
      "148642       not_int         not_lpsm       home          1U         CIB   \n",
      "148643       not_int         not_lpsm       home          4U         CIB   \n",
      "148644       not_int         not_lpsm       home          1U         CIB   \n",
      "148645       not_int         not_lpsm       home          1U         EXP   \n",
      "148646       not_int         not_lpsm       home          1U         CIB   \n",
      "\n",
      "       co-applicant_credit_type    age   Region Security_Type  Status  \n",
      "0                           CIB  65-74    south        direct       0  \n",
      "1                           CIB  35-44    south        direct       0  \n",
      "3                           EXP  45-54    south        direct       1  \n",
      "4                           EXP  25-34    south        direct       0  \n",
      "5                           CIB  55-64  central        direct       0  \n",
      "...                         ...    ...      ...           ...     ...  \n",
      "148642                      EXP  55-64    south        direct       0  \n",
      "148643                      CIB  25-34    south        direct       0  \n",
      "148644                      EXP  45-54    North        direct       0  \n",
      "148645                      EXP  55-64    North        direct       0  \n",
      "148646                      CIB  45-54    North        direct       0  \n",
      "\n",
      "[143961 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "# Identify and keep only non-numeric (categorical) columns\n",
    "categorical_cols = df.select_dtypes(exclude=['number']).columns.tolist()\n",
    "\n",
    "# Ensure the target column 'Status' is retained, even if numeric-coded\n",
    "if 'Status' not in categorical_cols:\n",
    "    categorical_cols.append('Status')\n",
    "\n",
    "# Create a new DataFrame containing only categorical features and the target\n",
    "cat_df = df[categorical_cols]\n",
    "\n",
    "# Drop rows with any missing categorical values to prepare for modeling\n",
    "cat_df = cat_df.dropna()\n",
    "\n",
    "# Print the resulting shape: (number of rows, number of categorical columns + target)\n",
    "print(cat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a377d",
   "metadata": {},
   "source": [
    "# Question 2 Decison Tress Algorithm Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eec05627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8607994998784427\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91     21740\n",
      "           1       0.87      0.51      0.64      7053\n",
      "\n",
      "    accuracy                           0.86     28793\n",
      "   macro avg       0.86      0.74      0.78     28793\n",
      "weighted avg       0.86      0.86      0.85     28793\n",
      "\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "                     feature  importance\n",
      "            credit_type_EQUI    0.680293\n",
      "   lump_sum_payment_not_lpsm    0.041412\n",
      "        Credit_Worthiness_l2    0.029704\n",
      "   Neg_ammortization_not_neg    0.025016\n",
      "            credit_type_CRIF    0.017708\n",
      "             credit_type_EXP    0.017106\n",
      "                Region_south    0.014100\n",
      "             loan_purpose_p3    0.013859\n",
      "           approv_in_adv_pre    0.013459\n",
      "business_or_commercial_nob/c    0.013370\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select only non-numeric (categorical) columns and ensure 'Status' is included\n",
    "categorical_cols = df.select_dtypes(exclude=['number']).columns.tolist()\n",
    "if 'Status' not in categorical_cols:\n",
    "    categorical_cols.append('Status')\n",
    "cat_df = df[categorical_cols].dropna()  # drop rows with missing categorical values\n",
    "\n",
    "# Prepare X and y\n",
    "#    - X: one-hot encoded categorical features\n",
    "#    - y: binary target (0 or 1)\n",
    "X = pd.get_dummies(cat_df.drop('Status', axis=1), drop_first=True)\n",
    "y = cat_df['Status'].astype(int)\n",
    "\n",
    "# Split into train and test sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# 5. Train the Decision Tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 6. Make predictions and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 7. Extract and display the top 10 feature importances\n",
    "feat_imp = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': clf.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(10)\n",
    "\n",
    "print(\"\\nTop 10 Feature Importances:\")\n",
    "print(feat_imp.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e5f773",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6a92320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8699683950960303\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92     21740\n",
      "           1       0.96      0.49      0.65      7053\n",
      "\n",
      "    accuracy                           0.87     28793\n",
      "   macro avg       0.91      0.74      0.78     28793\n",
      "weighted avg       0.88      0.87      0.85     28793\n",
      "\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "                     feature  importance\n",
      "            credit_type_EQUI    0.842405\n",
      "   lump_sum_payment_not_lpsm    0.051857\n",
      "   Neg_ammortization_not_neg    0.033999\n",
      "        Credit_Worthiness_l2    0.019381\n",
      "business_or_commercial_nob/c    0.017201\n",
      "                Gender_Joint    0.006880\n",
      "              loan_limit_ncf    0.005369\n",
      "co-applicant_credit_type_EXP    0.004261\n",
      "           approv_in_adv_pre    0.003601\n",
      "             loan_purpose_p2    0.001628\n"
     ]
    }
   ],
   "source": [
    "# Select only non-numeric (categorical) columns and ensure 'Status' is included\n",
    "categorical_cols = df.select_dtypes(exclude=['number']).columns.tolist()\n",
    "if 'Status' not in categorical_cols:\n",
    "    categorical_cols.append('Status')\n",
    "cat_df = df[categorical_cols].dropna()  # drop rows with missing categorical values\n",
    "\n",
    "# Prepare X and y\n",
    "#    - X: one-hot encoded categorical features\n",
    "#    - y: binary target (0 or 1)\n",
    "X = pd.get_dummies(cat_df.drop('Status', axis=1), drop_first=True)\n",
    "y = cat_df['Status'].astype(int)\n",
    "\n",
    "# 4. Split into train and test sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Train the Gradient Boosting classifier\n",
    "gbc = GradientBoostingClassifier(\n",
    "    n_estimators=100,      # number of trees\n",
    "    learning_rate=0.1,     # step size shrinkage\n",
    "    max_depth=3,           # depth of each tree\n",
    "    random_state=42\n",
    ")\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "#  Make predictions and evaluate\n",
    "y_pred = gbc.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Extract and display the top 10 feature importances\n",
    "feat_imp = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': gbc.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(10)\n",
    "\n",
    "print(\"\\nTop 10 Feature Importances:\")\n",
    "print(feat_imp.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a849d2",
   "metadata": {},
   "source": [
    "# Question 3 Comprehensive Model development Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b213008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     22404\n",
      "           1       1.00      1.00      1.00      7326\n",
      "\n",
      "    accuracy                           1.00     29730\n",
      "   macro avg       1.00      1.00      1.00     29730\n",
      "weighted avg       1.00      1.00      1.00     29730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning\n",
    "#   • Strip whitespace from object columns\n",
    "#   • Standardize text to lowercase\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col] = df[col].str.strip().str.lower()\n",
    "\n",
    "# Feature engineering (example)\n",
    "#   • Create debt_to_income_ratio if not already present\n",
    "if 'debt_to_income_ratio' not in df.columns and {'debt', 'income'}.issubset(df.columns):\n",
    "    df['debt_to_income_ratio'] = df['debt'] / df['income']\n",
    "\n",
    "#   • Bin age into broader groups (ordinal feature)\n",
    "if 'age' in df.columns and df['age'].dtype == 'object':\n",
    "    age_mapping = {\n",
    "        '18-24': 1, '25-34': 2,\n",
    "        '35-44': 3, '45-54': 4,\n",
    "        '55-64': 5, '65-74': 6,\n",
    "        '75+': 7\n",
    "    }\n",
    "    df['age_group'] = df['age'].map(age_mapping)\n",
    "\n",
    "# Define feature sets\n",
    "target = 'Status'\n",
    "all_features = df.columns.drop(target)\n",
    "\n",
    "# Identify column types\n",
    "numeric_features   = df[all_features].select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "categorical_feats  = df[all_features].select_dtypes(include=['object','category']).columns.tolist()\n",
    "ordinal_feats      = ['age_group'] if 'age_group' in df.columns else []\n",
    "\n",
    "# Handling missing values & Encoding & Scaling\n",
    "#    • Numeric: impute with median + standard scale\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler',   StandardScaler())\n",
    "])\n",
    "\n",
    "#    • Ordinal: impute with most frequent (or constant) — no scaling\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "#    • Categorical: impute with constant 'missing' + one‐hot encode\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot',  OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Assemble into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num',    numeric_transformer,   numeric_features),\n",
    "    ('ord',    ordinal_transformer,   ordinal_feats),\n",
    "    ('cat',    categorical_transformer, categorical_feats),\n",
    "], remainder='drop')  # drop any other columns\n",
    "\n",
    "# 8. (Optional) Wrap in a Pipeline with your model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = Pipeline(steps=[\n",
    "    ('preproc', preprocessor),\n",
    "    ('model',   GradientBoostingClassifier(\n",
    "                    n_estimators=100,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=3,\n",
    "                    random_state=42))\n",
    "])\n",
    "\n",
    "# 9. Train/test split and fit\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df[all_features]\n",
    "y = df[target].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 10. Evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d0ea77",
   "metadata": {},
   "source": [
    "# Question 4 Performance Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70862f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_curve, auc, precision_recall_curve,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "\n",
    "# Fit best model or baseline\n",
    "best_model = grid.best_estimator_  # or use fitted pipeline .fit(...) earlier\n",
    "y_pred  = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Primary metrics\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred))\n",
    "print(\"F1-Score :\", f1_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Evaluations\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# 2. Precision-Recall Curve\n",
    "prec, rec, _ = precision_recall_curve(y_test, y_proba)\n",
    "plt.figure(); plt.plot(rec, prec); plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\"); plt.show()\n",
    "\n",
    "# 3. ROC Curve & AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(); plt.plot(fpr, tpr); plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC Curve (AUC={roc_auc:.3f})\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
