{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4da69c55",
   "metadata": {},
   "source": [
    "# Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9caddd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # For reading and manipulating structured data (like CSV files)\n",
    "import pandas as pd # For numerical operations and array handling\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "#Imports for BERT algorithm\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dc96cc",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fb1ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Dataset/results.csv') #Using pandas to load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37af71f7",
   "metadata": {},
   "source": [
    "# Question 1 Dataset description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7abcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So we are trying to predict  the outcome(win/draw/loss) based on the home team \n",
    "#Win-- if home_score > away_score\n",
    "#Draw-- if scores are equal\n",
    "#Loss-- if home_score < away_score\n",
    "\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "X = df[['home_team', 'away_team', 'tournament', 'city', 'country', 'neutral']]\n",
    "y = df['result']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a377d",
   "metadata": {},
   "source": [
    "# Question 2 Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec05627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classification target\n",
    "df['result'] = df.apply(\n",
    "    lambda row: 'Win' if row['home_score'] > row['away_score']\n",
    "    else 'Loss' if row['home_score'] < row['away_score']\n",
    "    else 'Draw',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Convert date to datetime and extract year\n",
    "df['year'] = pd.to_datetime(df['date']).dt.year\n",
    "\n",
    "# Create home advantage flag (1 = home, 0 = neutral)\n",
    "df['home_advantage'] = df['neutral'].apply(lambda x: 0 if x else 1)\n",
    "\n",
    "# Count previous head-to-head matchups (proxy for historical rivalry)\n",
    "df['matchup'] = df['home_team'] + \"_vs_\" + df['away_team']\n",
    "df['matchup_count'] = df.groupby('matchup').cumcount()\n",
    "\n",
    "# ===================== Select Features and Target =====================\n",
    "X = df[['home_team', 'away_team', 'tournament', 'home_advantage', 'year', 'matchup_count']]\n",
    "y = df['result']\n",
    "\n",
    "# ===================== Preprocessing =====================\n",
    "cat_features = ['home_team', 'away_team', 'tournament']\n",
    "num_features = ['home_advantage', 'year', 'matchup_count']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features),\n",
    "    ('num', StandardScaler(), num_features)\n",
    "])\n",
    "\n",
    "# ===================== Build Pipeline with SMOTE and Gradient Boosting =====================\n",
    "pipeline = ImbPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('clf', GradientBoostingClassifier(\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.3,\n",
    "        max_depth=4,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# ===================== Cross-Validation =====================\n",
    "scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"Average CV Accuracy: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e5f773",
   "metadata": {},
   "source": [
    "# Logistic Regression algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a92320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classification target\n",
    "df['result'] = df.apply(\n",
    "    lambda row: 'Win' if row['home_score'] > row['away_score']\n",
    "    else 'Loss' if row['home_score'] < row['away_score']\n",
    "    else 'Draw',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Feature engineering â€“ only using pre-match data\n",
    "df['year'] = pd.to_datetime(df['date']).dt.year\n",
    "df['home_advantage'] = df['neutral'].apply(lambda x: 0 if x else 1)\n",
    "df['is_final'] = df['tournament'].str.lower().str.contains('final').astype(int)\n",
    "df['is_friendly'] = df['tournament'].str.lower().str.contains('friendly').astype(int)\n",
    "\n",
    "#Use only features that are known before the match\n",
    "X = df[['home_team', 'away_team', 'tournament', 'home_advantage', 'year', 'is_final', 'is_friendly']]\n",
    "y = df['result']\n",
    "\n",
    "# Categorical and numeric features\n",
    "cat_features = ['home_team', 'away_team', 'tournament']\n",
    "num_features = ['home_advantage', 'year', 'is_final', 'is_friendly']\n",
    "\n",
    "# Preprocessing: encode categories, scale numbers\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features),\n",
    "    ('num', StandardScaler(), num_features)\n",
    "])\n",
    "\n",
    "# Train/test split (stratified to maintain class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# Build pipeline with Logistic Regression\n",
    "lr_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', LogisticRegression(\n",
    "        multi_class='multinomial',\n",
    "        solver='lbfgs',\n",
    "        max_iter=1000,\n",
    "        C=0.1,\n",
    "        verbose=1  # optional: shows training progress\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit and evaluate\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "y_pred = lr_pipeline.predict(X_test)\n",
    "\n",
    "# Report results\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a849d2",
   "metadata": {},
   "source": [
    "# Question 3 Comprehensive Model development Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b213008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================= 1. DATA CLEANING =======================\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"results.csv\")\n",
    "\n",
    "# Drop rows with essential missing values (cleaning step)\n",
    "df = df.dropna(subset=['home_team', 'away_team', 'tournament', 'date'])\n",
    "\n",
    "# Convert date string to datetime object\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# ======================= 2. TARGET CREATION =======================\n",
    "\n",
    "# Create categorical target: 'Win', 'Draw', 'Loss'\n",
    "df['result'] = df.apply(\n",
    "    lambda row: 'Win' if row['home_score'] > row['away_score']\n",
    "    else 'Loss' if row['home_score'] < row['away_score']\n",
    "    else 'Draw',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ======================= 3. FEATURE ENGINEERING =======================\n",
    "\n",
    "# Create year feature from date\n",
    "df['year'] = df['date'].dt.year\n",
    "\n",
    "# Create home_advantage (1 if not neutral, else 0)\n",
    "df['home_advantage'] = df['neutral'].apply(lambda x: 0 if x else 1)\n",
    "\n",
    "# Add binary flags for whether the tournament is a final or friendly\n",
    "df['is_final'] = df['tournament'].str.lower().str.contains('final').astype(int)\n",
    "df['is_friendly'] = df['tournament'].str.lower().str.contains('friendly').astype(int)\n",
    "\n",
    "# ======================= 4. FEATURE SELECTION =======================\n",
    "\n",
    "# Use only features available *before* the match\n",
    "X = df[['home_team', 'away_team', 'tournament', 'home_advantage', 'year', 'is_final', 'is_friendly']]\n",
    "y = df['result']\n",
    "\n",
    "# ======================= 5. MISSING VALUE HANDLING =======================\n",
    "# Already done via dropna above. No further imputation needed in this case.\n",
    "\n",
    "# ======================= 6. ENCODING & SCALING =======================\n",
    "\n",
    "# Define categorical and numerical columns\n",
    "cat_features = ['home_team', 'away_team', 'tournament']\n",
    "num_features = ['home_advantage', 'year', 'is_final', 'is_friendly']\n",
    "\n",
    "# Apply OneHotEncoder to categorical features, StandardScaler to numeric features\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features),\n",
    "    ('num', StandardScaler(), num_features)\n",
    "])\n",
    "\n",
    "# ======================= 7. TRAIN-TEST SPLIT =======================\n",
    "\n",
    "# Stratified split to maintain class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# ======================= 8. LOGISTIC REGRESSION MODEL =======================\n",
    "\n",
    "# Build a pipeline: preprocess + Logistic Regression\n",
    "logistic_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', LogisticRegression(\n",
    "        multi_class='multinomial',\n",
    "        solver='lbfgs',\n",
    "        max_iter=1000,\n",
    "        C=0.1,             # Regularization to reduce overfitting\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit the model to training data\n",
    "logistic_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on test data\n",
    "y_pred_lr = logistic_pipeline.predict(X_test)\n",
    "print(\"ðŸ“˜ Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"ðŸ“˜ Classification Report:\\n\", classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# Perform 5-fold cross-validation for robustness\n",
    "lr_cv_score = cross_val_score(logistic_pipeline, X, y, cv=5, scoring='accuracy')\n",
    "print(\"ðŸ“˜ Logistic CV Accuracy:\", lr_cv_score.mean())\n",
    "\n",
    "# ======================= 9. GRADIENT BOOSTING MODEL =======================\n",
    "\n",
    "# Build a pipeline: preprocess + Gradient Boosting\n",
    "boosting_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', GradientBoostingClassifier(\n",
    "        n_estimators=300,       # More trees for better learning\n",
    "        learning_rate=0.05,     # Slower learning for better generalization\n",
    "        max_depth=5,            # Moderate tree depth\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "boosting_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_gb = boosting_pipeline.predict(X_test)\n",
    "print(\"ðŸŒ² Gradient Boosting Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(\"ðŸŒ² Gradient Boosting Report:\\n\", classification_report(y_test, y_pred_gb))\n",
    "\n",
    "# Cross-validation to compare generalization\n",
    "gb_cv_score = cross_val_score(boosting_pipeline, X, y, cv=5, scoring='accuracy')\n",
    "print(\"ðŸŒ² Gradient Boosting CV Accuracy:\", gb_cv_score.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ed3f7e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62d0ea77",
   "metadata": {},
   "source": [
    "# Question 4 Performance Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2f5859",
   "metadata": {},
   "source": [
    "# 4.1 Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240b86eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities (needed for ROC/AUC)\n",
    "y_proba_lr = logistic_pipeline.predict_proba(X_test)\n",
    "y_proba_gb = boosting_pipeline.predict_proba(X_test)\n",
    "\n",
    "# Predict labels\n",
    "y_pred_lr = logistic_pipeline.predict(X_test)\n",
    "y_pred_gb = boosting_pipeline.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print(\"ðŸ”µ Logistic Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"ðŸŸ¢ Gradient Boosting Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nðŸ”µ Logistic Classification Report:\\n\", classification_report(y_test, y_pred_lr))\n",
    "print(\"\\nðŸŸ¢ Gradient Boosting Classification Report:\\n\", classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9de5c2",
   "metadata": {},
   "source": [
    "# 4.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70862f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix for Logistic\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr, labels=['Win', 'Draw', 'Loss'])\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', xticklabels=['Win', 'Draw', 'Loss'], yticklabels=['Win', 'Draw', 'Loss'])\n",
    "plt.title(\"ðŸ”µ Confusion Matrix: Logistic Regression\")\n",
    "plt.ylabel(\"Actual\"); plt.xlabel(\"Predicted\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffb3077",
   "metadata": {},
   "source": [
    "# 4.3 ROC Curve (Multiclass using One-vs-Rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Binarize the output for ROC\n",
    "classes = ['Win', 'Draw', 'Loss']\n",
    "y_test_bin = label_binarize(y_test, classes=classes)\n",
    "\n",
    "# Plot ROC for each class (Logistic)\n",
    "for i in range(len(classes)):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_proba_lr[:, i])\n",
    "    auc = roc_auc_score(y_test_bin[:, i], y_proba_lr[:, i])\n",
    "    plt.plot(fpr, tpr, label=f\"{classes[i]} (AUC = {auc:.2f})\")\n",
    "\n",
    "plt.title(\"ðŸ”µ ROC Curve (Logistic Regression)\")\n",
    "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f829b8",
   "metadata": {},
   "source": [
    "# 4.4 Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3932d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Precision-Recall Curve for each class (Logistic)\n",
    "for i in range(len(classes)):\n",
    "    precision, recall, _ = precision_recall_curve(y_test_bin[:, i], y_proba_lr[:, i])\n",
    "    plt.plot(recall, precision, label=f\"{classes[i]}\")\n",
    "\n",
    "plt.title(\"ðŸ”µ Precision-Recall Curve (Logistic Regression)\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
