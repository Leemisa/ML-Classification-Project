{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4da69c55",
   "metadata": {},
   "source": [
    "# Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9caddd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # For reading and manipulating structured data (like CSV files)\n",
    "import pandas as pd # For numerical operations and array handling\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dc96cc",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fb1ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Dataset/results.csv') #Using pandas to load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37af71f7",
   "metadata": {},
   "source": [
    "# Question 1 Dataset description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7abcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So we are trying to predict  the outcome(win/draw/loss) based on the home team \n",
    "#Win-- if home_score > away_score\n",
    "#Draw-- if scores are equal\n",
    "#Loss-- if home_score < away_score\n",
    "\n",
    "\n",
    "# Drop the 'id' column\n",
    "df = df.drop(columns=[0])\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a377d",
   "metadata": {},
   "source": [
    "# Question 2 Logistic Regression Algorithm Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec05627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8607994998784427\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91     21740\n",
      "           1       0.87      0.51      0.64      7053\n",
      "\n",
      "    accuracy                           0.86     28793\n",
      "   macro avg       0.86      0.74      0.78     28793\n",
      "weighted avg       0.86      0.86      0.85     28793\n",
      "\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "                     feature  importance\n",
      "            credit_type_EQUI    0.680293\n",
      "   lump_sum_payment_not_lpsm    0.041412\n",
      "        Credit_Worthiness_l2    0.029704\n",
      "   Neg_ammortization_not_neg    0.025016\n",
      "            credit_type_CRIF    0.017708\n",
      "             credit_type_EXP    0.017106\n",
      "                Region_south    0.014100\n",
      "             loan_purpose_p3    0.013859\n",
      "           approv_in_adv_pre    0.013459\n",
      "business_or_commercial_nob/c    0.013370\n"
     ]
    }
   ],
   "source": [
    "# Define features and target\n",
    "X = df[['home_team', 'away_team', 'tournament', 'city', 'country', 'neutral']]\n",
    "y = df['result']\n",
    "\n",
    "# Preprocessing pipeline\n",
    "cat_features = ['home_team', 'away_team', 'tournament', 'city', 'country']\n",
    "bool_features = ['neutral']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', Pipeline([\n",
    "        ('impute', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), cat_features)\n",
    "], remainder='passthrough')  # Keep 'neutral' as-is\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# Pipeline with Logistic Regression\n",
    "lr_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=200))\n",
    "])\n",
    "\n",
    "lr_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e5f773",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6a92320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8699683950960303\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92     21740\n",
      "           1       0.96      0.49      0.65      7053\n",
      "\n",
      "    accuracy                           0.87     28793\n",
      "   macro avg       0.91      0.74      0.78     28793\n",
      "weighted avg       0.88      0.87      0.85     28793\n",
      "\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "                     feature  importance\n",
      "            credit_type_EQUI    0.842405\n",
      "   lump_sum_payment_not_lpsm    0.051857\n",
      "   Neg_ammortization_not_neg    0.033999\n",
      "        Credit_Worthiness_l2    0.019381\n",
      "business_or_commercial_nob/c    0.017201\n",
      "                Gender_Joint    0.006880\n",
      "              loan_limit_ncf    0.005369\n",
      "co-applicant_credit_type_EXP    0.004261\n",
      "           approv_in_adv_pre    0.003601\n",
      "             loan_purpose_p2    0.001628\n"
     ]
    }
   ],
   "source": [
    "# Select only non-numeric (categorical) columns and ensure 'Status' is included\n",
    "categorical_cols = df.select_dtypes(exclude=['number']).columns.tolist()\n",
    "if 'Status' not in categorical_cols:\n",
    "    categorical_cols.append('Status')\n",
    "cat_df = df[categorical_cols].dropna()  # drop rows with missing categorical values\n",
    "\n",
    "# Prepare X and y\n",
    "#    - X: one-hot encoded categorical features\n",
    "#    - y: binary target (0 or 1)\n",
    "X = pd.get_dummies(cat_df.drop('Status', axis=1), drop_first=True)\n",
    "y = cat_df['Status'].astype(int)\n",
    "\n",
    "# 4. Split into train and test sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Train the Gradient Boosting classifier\n",
    "gbc = GradientBoostingClassifier(\n",
    "    n_estimators=100,      # number of trees\n",
    "    learning_rate=0.1,     # step size shrinkage\n",
    "    max_depth=3,           # depth of each tree\n",
    "    random_state=42\n",
    ")\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "#  Make predictions and evaluate\n",
    "y_pred = gbc.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Extract and display the top 10 feature importances\n",
    "feat_imp = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': gbc.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(10)\n",
    "\n",
    "print(\"\\nTop 10 Feature Importances:\")\n",
    "print(feat_imp.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a849d2",
   "metadata": {},
   "source": [
    "# Question 3 Comprehensive Model development Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b213008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     22404\n",
      "           1       1.00      1.00      1.00      7326\n",
      "\n",
      "    accuracy                           1.00     29730\n",
      "   macro avg       1.00      1.00      1.00     29730\n",
      "weighted avg       1.00      1.00      1.00     29730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning\n",
    "#   • Strip whitespace from object columns\n",
    "#   • Standardize text to lowercase\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col] = df[col].str.strip().str.lower()\n",
    "\n",
    "# Feature engineering (example)\n",
    "#   • Create debt_to_income_ratio if not already present\n",
    "if 'debt_to_income_ratio' not in df.columns and {'debt', 'income'}.issubset(df.columns):\n",
    "    df['debt_to_income_ratio'] = df['debt'] / df['income']\n",
    "\n",
    "#   • Bin age into broader groups (ordinal feature)\n",
    "if 'age' in df.columns and df['age'].dtype == 'object':\n",
    "    age_mapping = {\n",
    "        '18-24': 1, '25-34': 2,\n",
    "        '35-44': 3, '45-54': 4,\n",
    "        '55-64': 5, '65-74': 6,\n",
    "        '75+': 7\n",
    "    }\n",
    "    df['age_group'] = df['age'].map(age_mapping)\n",
    "\n",
    "# Define feature sets\n",
    "target = 'Status'\n",
    "all_features = df.columns.drop(target)\n",
    "\n",
    "# Identify column types\n",
    "numeric_features   = df[all_features].select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "categorical_feats  = df[all_features].select_dtypes(include=['object','category']).columns.tolist()\n",
    "ordinal_feats      = ['age_group'] if 'age_group' in df.columns else []\n",
    "\n",
    "# Handling missing values & Encoding & Scaling\n",
    "#    • Numeric: impute with median + standard scale\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler',   StandardScaler())\n",
    "])\n",
    "\n",
    "#    • Ordinal: impute with most frequent (or constant) — no scaling\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "#    • Categorical: impute with constant 'missing' + one‐hot encode\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot',  OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Assemble into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num',    numeric_transformer,   numeric_features),\n",
    "    ('ord',    ordinal_transformer,   ordinal_feats),\n",
    "    ('cat',    categorical_transformer, categorical_feats),\n",
    "], remainder='drop')  # drop any other columns\n",
    "\n",
    "# 8. (Optional) Wrap in a Pipeline with your model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = Pipeline(steps=[\n",
    "    ('preproc', preprocessor),\n",
    "    ('model',   GradientBoostingClassifier(\n",
    "                    n_estimators=100,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=3,\n",
    "                    random_state=42))\n",
    "])\n",
    "\n",
    "# 9. Train/test split and fit\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df[all_features]\n",
    "y = df[target].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 10. Evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d0ea77",
   "metadata": {},
   "source": [
    "# Question 4 Performance Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70862f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_curve, auc, precision_recall_curve,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "\n",
    "# Fit best model or baseline\n",
    "best_model = grid.best_estimator_  # or use fitted pipeline .fit(...) earlier\n",
    "y_pred  = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Primary metrics\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred))\n",
    "print(\"F1-Score :\", f1_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Evaluations\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# 2. Precision-Recall Curve\n",
    "prec, rec, _ = precision_recall_curve(y_test, y_proba)\n",
    "plt.figure(); plt.plot(rec, prec); plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\"); plt.show()\n",
    "\n",
    "# 3. ROC Curve & AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(); plt.plot(fpr, tpr); plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC Curve (AUC={roc_auc:.3f})\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
